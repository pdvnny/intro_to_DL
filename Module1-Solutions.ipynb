{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40914dd3-963b-40e3-aa78-1eccbfa5180b",
   "metadata": {},
   "source": [
    "### Parker Dunn\n",
    "\n",
    "## COURSERA - Introduction to Deep Learning\n",
    "\n",
    "### Module 1 - Week 1: Neural Networks - SOLUTIONS\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44176351-405c-4ca9-9601-4232f0166d18",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d671ec0-fca3-4940-9651-bef4850e2a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  [0 0]  y =  1\n",
      "x =  [0 1]  y =  0\n",
      "x =  [1 0]  y =  0\n",
      "x =  [1 1]  y =  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "W1, b1 = np.array([[1,1], [-1,-1]]), np.array([-1.5, 0.5])\n",
    "W2, b2 = np.array([[1, 1]]), np.array([-0.5])\n",
    "\n",
    "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "\n",
    "for ii, x in enumerate(X): \n",
    "    a1 = np.array(np.dot(W1, x) + b1 > 0, dtype=int)\n",
    "    a2 = np.array(np.dot(W2, a1) + b2 > 0, dtype=int)\n",
    "    print(\"x = \", x, \" y = \", a2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b6a451-8df7-4a56-b2fa-82d2f4db75d6",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cf5ff1a-0b3e-4936-a89f-b58dc1725206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(self, x):\n",
    "        \"\"\"\n",
    "        take an feature vector and propagate through network \n",
    "        \n",
    "        :param x: input feature vector \n",
    "        \"\"\"\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.reshape(-1, 1)\n",
    "        # TODO: step 1. Initialize activation on initial layer to x \n",
    "        ### BEGIN SOLUTION\n",
    "        self.a[0] = x  \n",
    "        ### END SOLUTION\n",
    "        \n",
    "        ## TODO: step 2-4. Loop over layers and compute activities and activations \n",
    "        ### BEGIN SOLUTION\n",
    "        for ll in range(self.L - 1):\n",
    "            self.z[ll + 1] = np.dot(self.W[ll], self.a[ll]) + self.b[ll]\n",
    "            self.a[ll + 1] = self.g(self.z[ll + 1])\n",
    "        ### END SOLUTION  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1790204-534a-40ab-9ca3-f256904592ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(self, x, y):\n",
    "        \"\"\"\n",
    "        Back propagation to get derivatives of C wrt weights and biases for given training example\n",
    "        \n",
    "        :param x: training features  \n",
    "        :param y: vector-encoded label \n",
    "        \"\"\"\n",
    "        \n",
    "        if len(y.shape) == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "        \n",
    "        # TODO: step 1. forward prop training example to fill in activities and activations \n",
    "        ### BEGIN SOLUTION\n",
    "        self.forward_prop(x)\n",
    "        ### END SOLUTION\n",
    "        \n",
    "        # TODO: step 2. compute deltas on output layer (Hint: python index numbering starts from 0 ends at N-1)\n",
    "        ### BEGIN SOLUTION\n",
    "        self.delta[self.L - 1] = self.g_prime(self.z[self.L - 1]) * self.grad_loss(self.a[self.L-1], y)\n",
    "        ### END SOLUTION\n",
    "        \n",
    "        # TODO: step 3-6. loop backward through layers, backprop deltas, compute dWs and dbs\n",
    "        ### BEGIN SOLUTION\n",
    "        for ll in range(self.L-2, -1, -1): \n",
    "            self.dW[ll] = np.dot(self.delta[ll + 1], self.a[ll].T)\n",
    "            self.db[ll] = self.delta[ll + 1]\n",
    "            self.delta[ll] = np.dot(self.W[ll].T, self.delta[ll + 1]) * self.g_prime(self.z[ll])\n",
    "        ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeffae62-9a56-41ef-98ff-c3a8a93305d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, X_train, y_train, X_valid=None, y_valid=None,\n",
    "          eta=0.25, num_epochs=10, isPrint=True, isVis=False):\n",
    "    \"\"\"\n",
    "    Train the network with SGD \n",
    "\n",
    "    :param X_train: matrix of training features \n",
    "    :param y_train: matrix of vector-encoded labels \n",
    "    \"\"\"\n",
    "\n",
    "    # initialize shuffled indices \n",
    "    shuffled_inds = list(range(X_train.shape[0]))\n",
    "\n",
    "    # loop over training epochs (step 1.)\n",
    "    for ep in range(num_epochs):\n",
    "\n",
    "        # shuffle indices \n",
    "        np.random.shuffle(shuffled_inds)\n",
    "\n",
    "        # loop over training examples (step 2.) \n",
    "        for ind in shuffled_inds: \n",
    "\n",
    "            # step 3. back prop to get derivatives (partial score 4)\n",
    "            ### BEGIN SOLUTION\n",
    "            self.back_prop(X_train[ind, :], y_train[ind, :])\n",
    "            ### END SOLUTION\n",
    "\n",
    "            # step 4. update weights and biases\n",
    "            ### BEGIN SOLUTION\n",
    "            for ll in range(self.L - 1): # (partial score 2)\n",
    "                self.W[ll] = self.W[ll] - eta * self.dW[ll] # (partial score 2)\n",
    "                self.b[ll] = self.b[ll] - eta * self.db[ll] # (partial score 2)\n",
    "            ### END SOLUTION\n",
    "\n",
    "        # print mean loss every 10 epochs if requested \n",
    "        if isPrint and (ep % 10) == 0:\n",
    "            print(\"epoch {:3d}/{:3d}: \".format(ep, num_epochs), end=\"\")\n",
    "            print(\"  train loss: {:8.3f}\".format(self.compute_loss(X_train, y_train)), end=\"\")\n",
    "            if X_valid is not None:\n",
    "                print(\"  validation loss: {:8.3f}\".format(self.compute_loss(X_valid, y_valid)))\n",
    "            else:\n",
    "                print(\"\")\n",
    "\n",
    "        if isVis and (ep % 20) == 0:\n",
    "            self.pretty_pictures(X_train, y_train, decision_boundary=True, epoch=ep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2e9f7d-24de-4235-9eb6-4dbfacb40b3e",
   "metadata": {},
   "source": [
    "### The code below will throw an error because the `Network` class has not been implemented in this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdb2bfd-551f-4915-aa62-94fc6895720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, y_train = generate_data(300, \"moons\")\n",
    "X_valid, y_valid = generate_data(300, \"moons\")\n",
    "\n",
    "# Build a model and train using the train and validation data. Tweak model and training hyperparameters and display the results.\n",
    "nn = Network([2, 30, 15, 2])\n",
    "nn.train(X_train, y_train, X_valid, y_valid, eta=0.25, num_epochs=101, isPrint=True, isVis=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
